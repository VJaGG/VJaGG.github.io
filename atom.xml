<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WZQiang&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-12T02:50:07.318Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>你们跌倒了mei</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>cs231n-assignment2</title>
    <link href="http://yoursite.com/2020/07/12/cs231n-assignment2/"/>
    <id>http://yoursite.com/2020/07/12/cs231n-assignment2/</id>
    <published>2020-07-12T02:50:07.000Z</published>
    <updated>2020-07-12T02:50:07.318Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>cs231n assignment3</title>
    <link href="http://yoursite.com/2020/07/11/cs231n-assignment3/"/>
    <id>http://yoursite.com/2020/07/11/cs231n-assignment3/</id>
    <published>2020-07-11T03:06:08.000Z</published>
    <updated>2020-07-12T05:00:27.713Z</updated>
    
    <content type="html"><![CDATA[<p>作业三中总共有五个问题，前两个问题分别是自己实现一个RNN和LSTM来做图像captioning，问题三是对神经网络的几个可视化，问题四是我们经常看到的风格迁移，最后一个问题是生成对抗网络，下面将对每个问题进行详细的阐述。所有作业的实现都已经上传到<a href="https://github.com/VJaGG/cs231n-spring-2019" target="_blank" rel="noopener">GitHub</a>。</p><h2 id="Q1-Image-Captioning-with-Vanilla-RNNs"><a href="#Q1-Image-Captioning-with-Vanilla-RNNs" class="headerlink" title="Q1: Image Captioning with Vanilla RNNs"></a>Q1: Image Captioning with Vanilla RNNs</h2><p>在Q1和Q2所用到的训练数据集是<strong>Microsoft COCO</strong>，其中数据进行了预处理，全部的数据特征都是从VGG-16的fc7层中提取的，VGG网络是在ImageNet数据集上预训练好的。通过VGG网络提取的预处理的特征分别存储在<code>train2014_vgg16_fc7.h5</code>和<code>val2014_vgg16_fc7.h5</code>中。为了在速度和处理时间上节省内存，这里使用<strong>PCA</strong>对提取的特征进行了降维，将VGG-16提取的4096维度降到了512维，存储在<code>train2014_vgg16_fc7_pca.h5</code>和<code>val2014_vgg16_fc7_pca.h5</code>中。为了便于训练每个单词都有一个ID与其对应，这些映射存储在<code>coco2014_vocab.json</code>。下图为训练的数据集。训练中增加了几个特殊的token，在开始和结束的位置分别加了&lt;START&gt;和&lt;END&gt;标签，不常见的单词用&lt;&lt;UNK&gt;来替代，对于长度比较短的在&lt;END&gt;后面用&lt;NULL&gt;来进行补全。</p><body><table rules="none"><tr><td align="center" style="font-size:90%"> &lt;START&gt; a &lt;UNK&gt; bike learning up against the side of a building &lt;END&gt; </td><td align="center"> &lt;START&gt; a desk and chair with a computer and a lamp &lt;END&gt;</td></tr><tr><td><img src= "/img/loading.gif" data-src="/2020/07/11/cs231n-assignment3/test1.jpg"></td><td><img src= "/img/loading.gif" data-src="/2020/07/11/cs231n-assignment3/test2.jpg"></td></tr></table></body>  <p><strong>RNN</strong>的实现代码在<code>cs231n/rnn_layers.py</code>中，其中<strong>RNN</strong>的主要公式如下：  </p><center>$z=W_xx_t + W_hh_{t-1}+b$</center>  <center>$h_{t} = \tanh(z)$</center>  作业中会对RNN的前向传播和反向传播分别进行实现，前向传播和反向传播的代码如下:  <p>前向传播    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span><span class="params">(x, prev_h, Wx, Wh, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Run the forward pass for a single timestep of a vanilla RNN that uses a tanh</span></span><br><span class="line"><span class="string">    activation function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input data has dimension D, the hidden state has dimension H, and we use</span></span><br><span class="line"><span class="string">    a minibatch size of N.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data for this timestep, of shape (N, D).</span></span><br><span class="line"><span class="string">    - prev_h: Hidden state from previous timestep, of shape (N, H) </span></span><br><span class="line"><span class="string">    - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) </span></span><br><span class="line"><span class="string">    - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) </span></span><br><span class="line"><span class="string">    - b: Biases of shape (H,) 偏置</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - next_h: Next hidden state, of shape (N, H) </span></span><br><span class="line"><span class="string">    - cache: Tuple of values needed for the backward pass. </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    next_h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    z = np.dot(x, Wx) + np.dot(prev_h, Wh) + b</span><br><span class="line">    next_h = np.tanh(z)</span><br><span class="line">    cache = (x, prev_h, Wx, Wh, b, next_h)</span><br><span class="line">    <span class="keyword">return</span> next_h, cache</span><br></pre></td></tr></table></figure><p>反向传播  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span><span class="params">(dnext_h, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Backward pass for a single timestep of a vanilla RNN.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dnext_h: Gradient of loss with respect to next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Cache object from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradients of input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dprev_h: Gradients of previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradients of input-to-hidden weights, of shape (D, H)</span></span><br><span class="line"><span class="string">    - dWh: Gradients of hidden-to-hidden weights, of shape (H, H)</span></span><br><span class="line"><span class="string">    - db: Gradients of bias vector, of shape (H,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dprev_h, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    (x, prev_h, Wx, Wh, b, next_h) = cache</span><br><span class="line">    dz = (<span class="number">1</span> -  next_h**<span class="number">2</span>) * dnext_h</span><br><span class="line">    dx = np.dot(dz, Wx.T)</span><br><span class="line">    dprev_h = np.dot(dz, Wh.T)</span><br><span class="line">    dWx = np.dot(x.T, dz)</span><br><span class="line">    dWh = np.dot(prev_h.T, dz)</span><br><span class="line">    db = np.sum(dz, axis=<span class="number">0</span>) </span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>以上实现的反向传播和前向传播只是针对于当前时刻的。</p><h2 id="Q2-Image-Captioning-with-LSTMs"><a href="#Q2-Image-Captioning-with-LSTMs" class="headerlink" title="Q2: Image Captioning with LSTMs"></a>Q2: Image Captioning with LSTMs</h2><p>The Jupyter notebook <code>LSTM_Captioning.ipynb</code> will walk you through the<br>implementation of Long-Short Term Memory (LSTM) RNNs, and apply them to image<br>captioning on MS-COCO.</p><h2 id="Q3-Network-Visualization-Saliency-maps-Class-Visualization-and-Fooling-Images"><a href="#Q3-Network-Visualization-Saliency-maps-Class-Visualization-and-Fooling-Images" class="headerlink" title="Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images"></a>Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images</h2><p>The Jupyter notebooks <code>NetworkVisualization-TensorFlow.ipynb</code> /<code>NetworkVisualization-PyTorch.ipynb</code> will introduce the pretrained SqueezeNet model, compute gradients<br>with respect to images, and use them to produce saliency maps and fooling<br>images. Please complete only one of the notebooks (TensorFlow or PyTorch). No extra credit will be awardeded if you complete both notebooks.</p><h2 id="Q4-Style-Transfer"><a href="#Q4-Style-Transfer" class="headerlink" title="Q4: Style Transfer"></a>Q4: Style Transfer</h2><p>In the Jupyter notebooks <code>StyleTransfer-TensorFlow.ipynb</code>/<code>StyleTransfer-PyTorch.ipynb</code> you will learn how to create images with the content of one image but the style of another. Please complete only one of the notebooks (TensorFlow or PyTorch). No extra credit will be awardeded if you complete both notebooks.</p><h2 id="Q5-Generative-Adversarial-Networks"><a href="#Q5-Generative-Adversarial-Networks" class="headerlink" title="Q5: Generative Adversarial Networks"></a>Q5: Generative Adversarial Networks</h2><p>In the Jupyter notebooks <code>GANS-TensorFlow.ipynb</code>/<code>GANS-PyTorch.ipynb</code> you will learn how to generate images that match a training dataset, and use these models to improve classifier performance when training on a large amount of unlabeled data and a small amount of labeled data. Please complete only one of the notebooks (TensorFlow or PyTorch). No extra credit will be awarded if you complete both notebooks.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;作业三中总共有五个问题，前两个问题分别是自己实现一个RNN和LSTM来做图像captioning，问题三是对神经网络的几个可视化，问题四是我们经常看到的风格迁移，最后一个问题是生成对抗网络，下面将对每个问题进行详细的阐述。所有作业的实现都已经上传到&lt;a href=&quot;http
      
    
    </summary>
    
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>hello world</title>
    <link href="http://yoursite.com/2020/07/10/hello-world/"/>
    <id>http://yoursite.com/2020/07/10/hello-world/</id>
    <published>2020-07-10T13:52:31.640Z</published>
    <updated>2020-07-11T03:35:07.343Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
</feed>

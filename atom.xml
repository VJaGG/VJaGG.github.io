<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>WZQiang&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-01T14:15:35.099Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>你们跌倒了mei</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Recurrent Networks：Stability analysis and LSTMs</title>
    <link href="http://yoursite.com/2020/08/24/cmu11-785-rnn2/"/>
    <id>http://yoursite.com/2020/08/24/cmu11-785-rnn2/</id>
    <published>2020-08-24T13:21:28.000Z</published>
    <updated>2020-09-01T14:15:35.099Z</updated>
    
    <content type="html"><![CDATA[<h2 id="“BIBO”-Stability"><a href="#“BIBO”-Stability" class="headerlink" title="“BIBO” Stability"></a>“BIBO” Stability</h2><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/1.png" height="230" width="600">  <ul><li>Time-delay structures have bounded output if  <ol><li>The function $f()$ has bounded output for bounded input(which is true of almost every activation function)   </li><li>$X(t)$ is bounded</li></ol></li><li>“Bounded Input Bounded Output” stability<br> This is a highly desirable characteristic  </li></ul><p>下面的部分来分析RNN是否具有”BIBO”的性质，为了便于分析，课程中先是用线性的激活函数来分析后面进行推广。  </p><h2 id="Linear-systems"><a href="#Linear-systems" class="headerlink" title="Linear systems"></a>Linear systems</h2><ul><li>Easier to analyze linear systems  <ol><li>Will attempt to extrapolate to non-linear systems subsequently</li></ol></li><li>All activations are identity functions  </li></ul><p>所以在以下的分析中<br>$$z_k=W_{h}h_{k-1}+W_{x}x_{k}$$ $$h_{k}=z_{k}$$  </p><blockquote><p>解：综合上面两个等式可以得到<br>$h_k=W_{h}h_{k-1}+W_{x}x_{k}$<br>$h_{k-1}=W_{h}h_{k-2}+W_{x}x_{k-1}$<br>将第二个等式带入第一个得<br>$h_k=W_h^2h_{k-2}+W_hW_{x}x_{k-1}+W_{x}x_{k}$<br>以此递推下去可以得到<br>$h_k=W_{h}^{k+1}h_{-1}+W_{h}^{k}W_{x}x_{0}+W_{h}^{k-1}W_{x}x_{1}+W_{h}^{k-2}W_{x}x_{2}+…+W_{h}^{2}W_{x}x_{k-2}+W_{h}W_{x}x_{k-1}+W_{x}x_{k}$<br>注：$W_{h}^kW_{x}x_0$对应着在$t=0$时刻输入为$x_0$的项，其它的项全为0，其它的项类似，这边引入了一个新的函数$H_{k}(x_i)$，例如：<br>$H_{k}(x_0)=h_{k}(h_{-1}=0, x_0=x_0, x_1=0, x_2=0,…)$相当于只有$x_{0}$处有值，其它位置为0。<br>则上述等式等价为：<br>$h_{k}=H_k(h_{-1})+H_k(x_0)+H_k(x_1)+H_k(x_2)+…$<br>针对其中的一项$H_k(x_0)=W_{h}^kW_xx_0=x_0(W_h^kW_x1_0))=x_0H_k(1_0)$<br>其中$H_k(1_t)$是在时刻t的输入对最后输出$h_{k}$的影响。其中输入为[0 0 0 0…1 0 0]在t时刻的输入为1其它时刻为0，同时$h_1$也可以按相同的方式处理。所以最终可以等价于<br>$h_{k}=h_{-1}H_k(1_{-1})+x_0H_k(1_0)+x_1H_k(1_1)+x_2H_k(1_2)+…$</p></blockquote><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/2.png" height="230" width="700">    <blockquote><p>在<strong>RNN</strong>中主要是对之前信息的记忆，老师在课上原话是”How well does it remember at an input at time 0”所以我们这边重点分析在$t=0$时刻的，因为其它时刻是类似的都是$H_k(1_x)$的形式(感觉上述所有的推导都是为了推导出每个隐藏状态都是相同的形式，然后分析其中一项就可以)。课程中这边又用新的方式定义了上述的操作<br>$h(t)=wh(t-1)+cx(t)$这个等式与$h_k=W_{h}h_{k-1}+W_{x}x_{k}$是等价的只是更换了表示，则同时$H_k(x_0)=W_{h}^kW_xx_0$这一项等价与$h_0(t)=w^tcx(0)$就是h(t)的展开表示中在0时刻的项为h_0(t)这个也是最后h(t)对0时刻信息保留的多少。<br>所以综上这边得到两项为 </p><ul><li>$h(t)=wh(t-1)+cx(t)$</li><li>$h_0(t)=w^tcx(0)$ (Response to a single input at 0)<br>$h_0(t)$的值就代表着记忆的信息多少</li></ul></blockquote><p>如图所示横坐标为t，每条曲线对应着不同的w值，这边是针对t时刻的输入时标量的形式，可以发现当w的值大于1的时候，函数会很快的以指数的形式增长(blow up)，当w小于1的时候，函数会值很快的下降(vanish)，所以对信息的记忆很大程度上依赖于w的值。<br><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/3.png" height="480" width="640">   </p><p>以上的分析是基于输入是标量形式的下面分析输入是向量形式的。</p><h2 id="Linear-recursions-Vector-version"><a href="#Linear-recursions-Vector-version" class="headerlink" title="Linear recursions: Vector version"></a>Linear recursions: Vector version</h2><p>$$h(t)=wh(t-1)+cx(t)$$ $$h_0(t)=w^tcx(0)$$  </p><blockquote><p>解：$W$是矩阵，可以分解为$W=U    \Lambda U^{-1}$,则根据线性代数矩阵特征值特征向量$Wu_i=\lambda_iu_i$，所以在W的特征向量所张成的空间中所有的向量都可以用特征向量的线性组合来表示，所以<br>这边假设$x’=Cx$则<br>$x’=a_1u_1+a_2u_2+…a_nu_n$<br>左右都乘以$W$得<br>$Wx’=a_1Wu_1+a_2Wu_2+…a_nWu_n$，<br>根据$Wu_i=\lambda_iu_i$化简得<br>$Wx’=a_1\lambda_1u_1+a_2\lambda_1u_2+…a_n\lambda_1u_n$<br>连乘$W$后得<br>$W^tx’=a_1\lambda_1^tu_1+a_2\lambda_1^tu_2+…a_n\lambda_1^tu_n$<br>$\displaystyle \lim_{x\to\infty}|W^tx’|=a_m\lambda_m^tu_m$<br>where $m=\underset {j}{argmax}\lambda_j$<br>综上课程中得到以下几个结论  </p></blockquote><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/5.png" height="230" width="845"><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/6.png" height="84" width="746"><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/8.png" height="80" width="750">  <img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/9.png" height="481" width="732">  <p>课程中老师也分析了向量的形式得到了相同的结果。  </p><h2 id="How-about-non-linearities-scaler"><a href="#How-about-non-linearities-scaler" class="headerlink" title="How about non-linearities(scaler)"></a>How about non-linearities(scaler)</h2><p>$$h(t)=f(wh(t-1)+cx(t))$$<br>下面分析当激活函数不是线性的时候，如图所示</p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/10.png" height="200" width="732">  <ul><li><em>sigmoid</em>(left):不管初始化的w值为多少，很快的饱和。</li><li><em>tanh</em>(middle):对初始化的w比较敏感，可以保留一定时间的信息但是最终也会饱和。</li><li><em>relu</em>(right):对初始的w值比较敏感，可能below up。</li></ul><p>下面这张图是当输入为负数的时候的结果图。<br><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/11.png" height="200" width="732">  </p><h2 id="Stability-Analysis"><a href="#Stability-Analysis" class="headerlink" title="Stability Analysis"></a>Stability Analysis</h2><p>课程中老师后面讲解了当输入为向量的时候，得到了相同的结论，综上只有<strong>tanh</strong>函数可以满足能够在短时间内的记忆(only the tanh activation gives us any reasonable behavior and still has very short “memory”)</p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/12.png" height="478" width="867">  <p>对于RNN网络的总结<br>• Excellent models for time-series analysis tasks<br> – Time-series prediction<br> – Time-series classification<br> – Sequence prediction..<br>  – They can even simplify problems that are difficult for MLPs</p><p>• But the memory isn’t all that great.<br>总上RNN不能够长期的记忆信息，即使使用tahn激活函数也是在短时间内的记忆，不能够满足长期记忆的任务。  </p><h2 id="The-Jacobian-of-the-hidden-layers-for-an-RNN"><a href="#The-Jacobian-of-the-hidden-layers-for-an-RNN" class="headerlink" title="The Jacobian of the hidden layers for an RNN"></a>The Jacobian of the hidden layers for an RNN</h2><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/14.png" height="252" width="773">  <p>如图中的$\nabla f_t()$是隐藏层的输出对于隐藏层输入的梯度，只是对激活函数的求导<br>$$h(t)=f(wh(t-1)+cx(t))$$  $$z=wh(t-1)+c(x)$$<br>这边的h和z都是向量，所以求导是矩阵，但是每个输入只和一个输出有关系，所以是对角矩阵。对于激活函数例如$sigmoid(), tanh(), relu()$它们的梯度总是小于1的，对于RNN最常用的激活函数是$tanh()$，$tanh$的梯度是永远不会大于1的，如图  </p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/15.png" height="221" width="693">   <p>所以对于上面的对角矩阵是有界的，因为对角线上的每一项都是对$tanh$的求导。所以乘以上述的矩阵就会缩放。<strong>Multiplication by the Jacobian is always a shrinking operation.</strong>  </p><p>对于<br>$Div(X)=D(f_N(W_{N-1}f_{N-1}(W_{N-2}f_{N-2}(…W_0X))))$<br>计算梯度得到<br>$\nabla_{f_k}Div=\nabla D·\nabla f_N·W_{N-1}·\nabla f_{N-1}·W_{N-2}…\nabla f_{k+1}W_k$<br>在上述的公式中当我们进行反向传播计算梯度的时候，当乘以Jacobian矩阵($\nabla f_N$)的时候，梯度就会shrink。在经过几层的方向传播，梯度就会被忘记。  </p><h2 id="Training-deep-networks"><a href="#Training-deep-networks" class="headerlink" title="Training deep networks"></a>Training deep networks</h2><p>如图在训练神经网络的时候，随着梯度的反向传播，梯度有可能消失</p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/16.png" height="363" width="563"> <h2 id="What-about-the-weights"><a href="#What-about-the-weights" class="headerlink" title="What about the weights"></a>What about the weights</h2><p>在RNN中，所有的权重的矩阵都是相同的</p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/17.png" height="326" width="552">   <h2 id="Exploding-Vanishing-gradients"><a href="#Exploding-Vanishing-gradients" class="headerlink" title="Exploding/Vanishing gradients"></a>Exploding/Vanishing gradients</h2><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/18.png" height="326" width="552">   <h2 id="Gradient-problems-in-deep-networks"><a href="#Gradient-problems-in-deep-networks" class="headerlink" title="Gradient problems in deep networks"></a>Gradient problems in deep networks</h2><p>在神经网络的前向传播中浅层的梯度可能消失或者爆炸，可能会造成不明显的或者不稳定的梯度的更新，而且会随着网络层的加深，问题变得严重。</p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/19.png" height="347" width="533">  <p>后面老师对比了不同激活函数的梯度消失</p><table rules="none"><tr><td><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/20.png" border="0"></td><td><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/21.png" border="0"></td></tr></table>  <table rules="none"><tr><td><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/22.png" border="0"></td><td><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/23.png" border="0"></td></tr></table>  <img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/24.png" height="201" width="904">  <h2 id="story-so-far"><a href="#story-so-far" class="headerlink" title="story so far"></a>story so far</h2><p>通过以上的实验，老师从前向传播中rnn对之前信息的记忆和在反向传播过程中梯度对网络更新两个方面进行了分析。得出了一下的结论。</p><ul><li><strong>Recurrent networks retain information from the infinite past in principle</strong></li><li><strong>In practice, they are poor at memorization</strong>  <ol><li>The hidden outputs can blow up, or shrink to zero depending on the Eigen values of the recurrent weights matrix</li><li>The memory is also a function of the activation of the hidden units <em>(Tanh activations are the most effective at retaining memory, but even they don’t hold it very long)</em></li></ol></li><li><strong>Deep networks also suffer from a “vanishing or exploding gradient” problem</strong><ol><li>The gradient of the error at the output gets concentrated into a small<br>number of parameters in the earlier layers, and goes to zero for others</li></ol></li></ul><hr><p>从以上的分析，针对RNN中存在着的这些问题，下面讲解LSTM。先将上面存在的两个问题再具体的描述一下。  </p><p>1、梯度在反向传播的过程中会消失</p><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/25.png" height="463" width="837"><p>2、在前向传播的过程中，前面的信息会被忘记<br><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/26.png" height="456" width="663"></p><h2 id="The-long-term-dependency-problem"><a href="#The-long-term-dependency-problem" class="headerlink" title="The long-term dependency problem"></a>The long-term dependency problem</h2><p>如图所示，如果pattern1和pattern2之间有太多的内容，RNN将会忘记pattern1。<br><img src= "/img/loading.gif" data-src="/2020/08/24/cmu11-785-rnn2/27.png" height="463" width="663"></p><h2 id="Exploding-Vanishiing-gradients"><a href="#Exploding-Vanishiing-gradients" class="headerlink" title="Exploding/Vanishiing gradients"></a>Exploding/Vanishiing gradients</h2><p>$$Y = f_{N}(\underline{W_{N-1}f_{N-1}}(\underline{W_{N-2}f_{N-2}}(…\underline{W_0X})))$$<br>$$\nabla_{f_k}Div=\nabla D·\nabla{f_N}·W_{N-1}\nabla{f_{N-1}·W_{N-2}}…\underline{\nabla{f_{k+1}W_{k}}}$$</p><ul><li>The memory retention of the network depends on the behavior of the underlined terms(网络对于以前信息的记忆主要取决于划线的部分)  <ol><li>Which in turn depends on the parameters $\color{blue}{W}$ rather than what it is trying to “remember”(主要是依赖于W而不是输入信息)</li></ol></li><li>Can we have a network that just “remembers” arbitrarily long, to be recalled on demand?  <ol><li>Not be directly dependent on vagaries(n.奇想，奇特行为; 异想天开; 怪异多变;) of network parameters, but rather on input-based determination of whether it must be remembered<br>所以针对这些问题是否可以将这些部分替换，怎样使得网路可以记忆任意长度的信息，当需要的时候。  </li></ol></li><li>Replace this with something that doesn’t fade or blow up?</li><li>Network that “retains” useful memory arbitrarily long, to<br>be recalled on demand?<ol><li>Input-based determination of whether it must be remembered(基于网络的输入来决定是否记忆)</li><li>Retain memories until a switch based on the input flags them<br>as ok to forget or remember less<br>$$Memory(k)\approx C(x)·\sigma_k(x)·\sigma_{k-1}(x)…\sigma_1(x)$$ $$\nabla_{f_k}Div \approx \nabla D\color{red}{C\sigma’<em>NC\sigma’</em>{N-1}C…\sigma’_k}$$</li></ol></li></ul><h2 id="Enter-the-LSTM"><a href="#Enter-the-LSTM" class="headerlink" title="Enter the LSTM"></a>Enter the LSTM</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;“BIBO”-Stability&quot;&gt;&lt;a href=&quot;#“BIBO”-Stability&quot; class=&quot;headerlink&quot; title=&quot;“BIBO” Stability&quot;&gt;&lt;/a&gt;“BIBO” Stability&lt;/h2&gt;&lt;img src= &quot;/img/l
      
    
    </summary>
    
    
    
      <category term="cmu11-785" scheme="http://yoursite.com/tags/cmu11-785/"/>
    
  </entry>
  
  <entry>
    <title>数据增广</title>
    <link href="http://yoursite.com/2020/08/23/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF/"/>
    <id>http://yoursite.com/2020/08/23/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF/</id>
    <published>2020-08-23T12:46:07.000Z</published>
    <updated>2020-08-23T12:55:40.423Z</updated>
    
    <content type="html"><![CDATA[<p>图像分类任务中，数据增广是一种非常有用的正则化方法，可以有效的提升图像分类的效果，尤其对于数据不足或者模型网络较大的场景。图像增广的方法可以分为3类，$\color{orange}{图像变换类}$， $\color{orange}{图像剪切类}$，$\color{orange}{图像混叠类}$。图像变换类是指对全图进行一些变换，图像裁剪类是指对图像以一定的方式遮挡部分区域的变换，图像混叠类是指对多张图进行混叠为一张新图的变换。</p><h2 id="1、图像变换类"><a href="#1、图像变换类" class="headerlink" title="1、图像变换类"></a>1、图像变换类</h2><h3 id="AutoAugment"><a href="#AutoAugment" class="headerlink" title="AutoAugment"></a>AutoAugment</h3><h3 id="RandomAugment"><a href="#RandomAugment" class="headerlink" title="RandomAugment"></a>RandomAugment</h3><h2 id="2、图像裁剪类"><a href="#2、图像裁剪类" class="headerlink" title="2、图像裁剪类"></a>2、图像裁剪类</h2><h3 id="CutOut"><a href="#CutOut" class="headerlink" title="CutOut"></a>CutOut</h3><p>$\color{orange}{Cutout}$在训练的时候随机把图片的一部分剪掉，这样能够提高模型的鲁棒性。CutOut可以理解为Dropout的一种扩展的操作，不同的是Dropout是对图像经过网络后生成的特征进行遮挡，而Cutout是直接对输入的图像进行遮挡，相当于Dropout对噪声的鲁棒性更好。作者在论文中进行了详细的说明，这样做有一下的两点优势：(1)通过Cutout可以模拟真实场景中主题被部分遮挡时的场景；(2)可以促进模型充分利用图像中更多的内容(context)来进行分类，防止网络只关注显著性的图像区域，从而发生过拟合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cutout</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""Randomly mask out one or more patches from an image.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        n_holes (int): Number of patches to cut out of each image.</span></span><br><span class="line"><span class="string">        length (int): The length (in pixels) of each square patch.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_holes, length)</span>:</span></span><br><span class="line">        self.n_holes = n_holes</span><br><span class="line">        self.length = length</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, img)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            img (Tensor): Tensor image of size (C, H, W).</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            Tensor: Image with n_holes of dimension length x length cut out of it.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        (w, h) = img.size</span><br><span class="line">        mask = np.ones((h, w, <span class="number">3</span>), dtype=np.int)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> n <span class="keyword">in</span> range(self.n_holes):</span><br><span class="line">            y = np.random.randint(h)</span><br><span class="line">            x = np.random.randint(w)</span><br><span class="line"></span><br><span class="line">            y1 = np.clip(y - self.length // <span class="number">2</span>, <span class="number">0</span>, h)</span><br><span class="line">            y2 = np.clip(y + self.length // <span class="number">2</span>, <span class="number">0</span>, h)</span><br><span class="line">            x1 = np.clip(x - self.length // <span class="number">2</span>, <span class="number">0</span>, w)</span><br><span class="line">            x2 = np.clip(x + self.length // <span class="number">2</span>, <span class="number">0</span>, w)</span><br><span class="line"></span><br><span class="line">            mask[y1: y2, x1: x2, :] = <span class="number">0</span></span><br><span class="line">        img = img * mask</span><br><span class="line">        <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><h3 id="Random-Erasing"><a href="#Random-Erasing" class="headerlink" title="Random Erasing"></a>Random Erasing</h3><p>$\color{orange}{Random erasing}$其实和cutout非常相似，也是一种模拟物体遮挡的数据增强方法，同样是为了解决训练出的模型在有遮挡的数据集上泛化能力比较差的问题。区别在于，cutout是把图片中随机选中的矩形区域的像素值置为0，相当于裁剪掉，Random erasing是用随机数或者数据集中像素的平均值来替换原来的像素值，而且，cutout每次裁剪的区域大小是固定的，Random erasing替换掉的区域大小是随机的，而且在Random erasing中，图片是以一定的概率接受该预处理的方法，生成掩码的尺寸大小与长宽比也是根据预设的超参数来随机生成的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomErasing</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, EPSILON=<span class="number">0.5</span>, sl=<span class="number">0.02</span>, sh=<span class="number">0.4</span>, r1=<span class="number">0.3</span>, mean=[<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>])</span>:</span></span><br><span class="line">        self.EPSILON = EPSILON</span><br><span class="line">        self.mean = mean</span><br><span class="line">        self.sl = sl</span><br><span class="line">        self.sh = sh</span><br><span class="line">        self.r1 = r1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, img)</span>:</span></span><br><span class="line">        <span class="comment"># (c, h, w)</span></span><br><span class="line">        <span class="keyword">if</span> random.uniform(<span class="number">0</span>, <span class="number">1</span>) &gt; self.EPSILON:</span><br><span class="line">            <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> attempt <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">            area = img.shape[<span class="number">1</span>] * img.shape[<span class="number">2</span>]</span><br><span class="line">            target_area = random.uniform(self.sl, self.sh) * area</span><br><span class="line">            aspect_ratio = random.uniform(self.r1, <span class="number">1</span>/self.r1)</span><br><span class="line"></span><br><span class="line">            h = int(round(math.sqrt(target_area * aspect_ratio)))</span><br><span class="line">            w = int(round(math.sqrt(target_area / aspect_ratio)))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> w &lt; img.shape[<span class="number">2</span>] <span class="keyword">and</span> h &lt; img.shape[<span class="number">1</span>]:</span><br><span class="line">                x1 = random.randint(<span class="number">0</span>, img.shape[<span class="number">1</span>] - h)</span><br><span class="line">                y1 = random.randint(<span class="number">0</span>, img.shape[<span class="number">2</span>] - w)</span><br><span class="line">                <span class="keyword">if</span> img.shape[<span class="number">0</span>] == <span class="number">3</span>:</span><br><span class="line">                    img[<span class="number">0</span>, x1:x1+h, y1:y1+w] = self.mean[<span class="number">0</span>]</span><br><span class="line">                    img[<span class="number">1</span>, x1:x1+h, y1:y1+w] = self.mean[<span class="number">1</span>]</span><br><span class="line">                    img[<span class="number">2</span>, x1:x1+h, y1:y1+w] = self.mean[<span class="number">2</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    img[<span class="number">0</span>, x1:x1+h, y1:y1+w] = self.mean[<span class="number">1</span>]</span><br><span class="line">                <span class="keyword">return</span> img</span><br><span class="line">        <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><h3 id="GridMask"><a href="#GridMask" class="headerlink" title="GridMask"></a>GridMask</h3><h2 id="3、图像混叠类"><a href="#3、图像混叠类" class="headerlink" title="3、图像混叠类"></a>3、图像混叠类</h2><h3 id="MixUp"><a href="#MixUp" class="headerlink" title="MixUp"></a>MixUp</h3><p>$\color{orange}{Mixup}$是最先提出的图像混叠的增广方案，其原理简单，方便实现，不仅在图像分类上，在目标检测上也可以取得不错的效果。为了便于实现，通常只对一个batch内的数据进行混叠，在CutMix中也是如此。MixUp在一个batch中的实现代码如下。下面的代码实现中有可能存在相同的两张照片混叠。MixUp的定义如下。  </p><p>$$\hat{x}=\lambda{x_{i}}+(1-\lambda)x_{j}$$<br>$$\hat{y}=\lambda{y_{i}}+(1-\lambda)y_{j}$$</p><p>其中$\lambda\in[0, 1]$是从$Beta(\alpha, \alpha)$中选择的随机数。我们使用MixUp后的数据进行训练$(\hat{x}, \hat{y})$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mixup_data</span><span class="params">(x, y, alpha=<span class="number">1.0</span>, use_cuda=True)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="string">'''Returns mixed inputs, pairs of targets, and lambda'''</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> alpha &gt; <span class="number">0</span>:</span><br><span class="line">        lam = np.random.beta(alpha, alpha)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        lam = <span class="number">1</span></span><br><span class="line">    batch_size = x.size()[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> use_cuda:</span><br><span class="line">        index = torch.randperm(batch_size).cuda()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        index = torch.randperm(batch_size)</span><br><span class="line"></span><br><span class="line">    mixed_x = lam * x + (<span class="number">1</span> - lam) * x[index, :]</span><br><span class="line">    y_a, y_b = y, y[index]</span><br><span class="line">    <span class="keyword">return</span> mixed_x, y_a, y_b, lam</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mixup_criterion</span><span class="params">(criterion, pred, y_a, y_b, lam)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> lam * criterion(pred, y_a) + (<span class="number">1</span> - lam) * criterion(pred, y_b)</span><br></pre></td></tr></table></figure><p>在训练中MixUp的调用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (input, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    input = input.cuda()</span><br><span class="line">    target = target.cuda()</span><br><span class="line">    mixed_x, y_a, y_b, lam = mixup_data(input, target)</span><br><span class="line">    output = model(mixed_x)</span><br><span class="line">    loss = mixup_criterion(criterion, output, y_a, y_b, lam)</span><br></pre></td></tr></table></figure><h3 id="CutMix"><a href="#CutMix" class="headerlink" title="CutMix"></a>CutMix</h3><h3 id="AugMix"><a href="#AugMix" class="headerlink" title="AugMix"></a>AugMix</h3><p>[1] <a href="https://zhuanlan.zhihu.com/p/142940546" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/142940546</a><br>[2] <a href="https://paddleclas.readthedocs.io/zh_CN/latest/advanced_tutorials/image_augmentation/ImageAugment.html" target="_blank" rel="noopener">https://paddleclas.readthedocs.io/zh_CN/latest/advanced_tutorials/image_augmentation/ImageAugment.html</a><br>[3] <a href="https://mp.weixin.qq.com/s?__biz=MzI4MjA0NDgxNA==&amp;mid=2650722499&amp;idx=1&amp;sn=b489bb77ba12be14df197fdc77893b22&amp;chksm=f3958022c4e20934aee7516645a415a379275423b1805da63e7419766ad38460e1f8cd18fc6d&amp;mpshare=1&amp;scene=23&amp;srcid=0303HrF8UEJNThmdJNHWNSqd#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzI4MjA0NDgxNA==&amp;mid=2650722499&amp;idx=1&amp;sn=b489bb77ba12be14df197fdc77893b22&amp;chksm=f3958022c4e20934aee7516645a415a379275423b1805da63e7419766ad38460e1f8cd18fc6d&amp;mpshare=1&amp;scene=23&amp;srcid=0303HrF8UEJNThmdJNHWNSqd#rd</a><br>[4] <a href="https://github.com/tengshaofeng/ResidualAttentionNetwork-pytorch/blob/master/Residual-Attention-Network/train_mixup.py" target="_blank" rel="noopener">https://github.com/tengshaofeng/ResidualAttentionNetwork-pytorch/blob/master/Residual-Attention-Network/train_mixup.py</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;图像分类任务中，数据增广是一种非常有用的正则化方法，可以有效的提升图像分类的效果，尤其对于数据不足或者模型网络较大的场景。图像增广的方法可以分为3类，$\color{orange}{图像变换类}$， $\color{orange}{图像剪切类}$，$\color{orang
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>bag of tricks for classification</title>
    <link href="http://yoursite.com/2020/08/23/classification/"/>
    <id>http://yoursite.com/2020/08/23/classification/</id>
    <published>2020-08-23T12:44:30.000Z</published>
    <updated>2020-08-23T12:56:02.880Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Linear-scaling-learning-rate"><a href="#Linear-scaling-learning-rate" class="headerlink" title="Linear scaling learning rate"></a>Linear scaling learning rate</h3><p>使用大的batch size可能会减慢模型的训练过程。对于凸优化的问题，随着batch size的增加，收敛的速度会降低，神经网络也有类似的验证结果。随着batch size的增大，处理相同数据量的速度会越来越快，但是到达相同精度所需要的epoch数量会越来越多。也就是说，相同的epoch数量，大的batch_size训练的模型比小的batch_size训练的模型相比，验证准确率会减小。在mini-batch随机梯度下降中，梯度下降的值是随机的，因为每一个batch的数据是随机的选择，增大batch size不会改变梯度的期望，但是会降低它的方差。也就是说，大的batch size会降低梯度中的噪声，所以我们可以通过增大学习率来加快收敛的速度。<br>在论文<strong>Bag of Tricks for Image Classiﬁcation with Convolutional Neural Networks</strong>中介绍的是，在ResNet原论文中，batch size为256时候学习率为0.1，当把batch size 变为一个比较大的数b的时候，学习率可以相应的改变为 $0.1 \times b/256$</p><h3 id="Label-smoothing"><a href="#Label-smoothing" class="headerlink" title="Label-smoothing"></a>Label-smoothing</h3><p>在分类问题中，最后一层一般是全连接层，输出对应着one-hot编码的标签(在pytorch中分类的交叉熵损失<em>nn.CrossEntropyLoss(input, target)</em>中target不是one-hot的而是类别的索引值，这边应该是内部实现直接用索引索引出损失)。这种编码的方式与通过交叉损失来计算损失可能存在一些问题。其中计算出的softmax的结果为每个类别的概率值。<br>$$q_i = \frac{\exp(z_i)}{\sum_j^k \exp(z_j)}$$<br>对于目标标签的定义为。</p><p>$$p_i=<br>\begin{cases}<br>1&amp; \text{$i=y$}\<br>0&amp; \text{$i \neq y$}<br>\end{cases}$$<br>交叉熵的计算公式为：<br>$$\mathcal{l(p, q)}=-\sum_i^kp_i\log q_i$$<br>将softmax的结果$q_i$带入上式得<br>$$\mathcal{l(p, q)}=-z_y+\log(\sum_j^k\exp(z_j))$$</p><p>所以以one-hot为目标，交叉损失为损失函数，最小化损失最终得到的最优的$z_y^*$为：  </p><p>$$z_y^*=<br>\begin{cases}<br>+\infty&amp; \text{$i=y$}\<br>-\infty&amp; \text{$i \neq y$}<br>\end{cases}$$  </p><p>这种方式会鼓励模型对不同类别的输出分数差异非常大，或者说，模型过分相信它的判断。但是，对于一个由多人标注的数据集，不同人标注的准则可能不同，每个人的标注也可能会有一些错误。模型对标签的过分相信会导致过拟合。也就是说，网络会驱使自身往正确标签和错误标签差值大的方向学习，在训练数据不足以表征所有的样本特征的情况下，这就会导致网络过拟合。</p><p>$$p_i=<br>\begin{cases}<br>1-\epsilon&amp; \text{$i=y$}\<br>\epsilon/(K-1)&amp; \text{$i \neq y$}<br>\end{cases}$$  </p><p>这种方式会鼓励模型对不同类别的输出分数差异非常大，或者说，模型过分相信它的判断。但是，对于一个由多人标注的数据集，不同人标注的准则可能不同，每个人的标注也可能会有一些错误。模型对标签的过分相信会导致过拟合。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothing</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, eps=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        super(LabelSmoothing, self).__init__()</span><br><span class="line">        self.eps = eps</span><br><span class="line">        <span class="keyword">if</span> self.eps &gt; <span class="number">0</span>:</span><br><span class="line">            self.criterion = nn.KLDivLoss(reduction=<span class="string">'batchmean'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.criterion = nn.NLLLoss()</span><br><span class="line">        self.confidence = <span class="number">1.0</span> - self.eps</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_smooth_label</span><span class="params">(self, num_classes)</span>:</span></span><br><span class="line">        smooth_label = torch.zeros(<span class="number">1</span>, num_classes)</span><br><span class="line">        smooth_label.fill_(self.eps / (num_classes - <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> smooth_label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, target)</span>:</span></span><br><span class="line">        scores = F.log_softmax(input, dim=<span class="number">1</span>)</span><br><span class="line">        num_classes = input.size(<span class="number">-1</span>)</span><br><span class="line">        target = target.view(<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.confidence &lt; <span class="number">1</span>:</span><br><span class="line">            classes = target.detach()</span><br><span class="line">            smooth_label = self._smooth_label(num_classes)</span><br><span class="line">            <span class="keyword">if</span> target.is_cuda:</span><br><span class="line">                smooth_label = smooth_label.cuda()</span><br><span class="line">            smooth_label = smooth_label.repeat(target.size(<span class="number">0</span>), <span class="number">1</span>) </span><br><span class="line">            smooth_label.scatter_(<span class="number">1</span>, classes.unsqueeze(<span class="number">1</span>), self.confidence)</span><br><span class="line">            target = smooth_label.detach()</span><br><span class="line">        loss = self.criterion(scores, target)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    outputs = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.7</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">                                 [<span class="number">0</span>, <span class="number">0.9</span>, <span class="number">0.2</span>, <span class="number">0.1</span>, <span class="number">0</span>],</span><br><span class="line">                                 [<span class="number">0</span>, <span class="number">0.9</span>, <span class="number">0.2</span>, <span class="number">0.1</span>, <span class="number">0</span>]])</span><br><span class="line">    labels = torch.LongTensor([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    criterion = LabelSmoothing(<span class="number">0.1</span>)</span><br><span class="line">    loss = criterion(outputs, labels)</span><br><span class="line">    print(loss)</span><br></pre></td></tr></table></figure><h3 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h3><p>[1] <a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">https://www.zhihu.com/question/41631631</a><br>[2] <a href="https://mp.weixin.qq.com/s?__biz=MzI4MjA0NDgxNA==&amp;mid=2650722499&amp;idx=1&amp;sn=b489bb77ba12be14df197fdc77893b22&amp;chksm=f3958022c4e20934aee7516645a415a379275423b1805da63e7419766ad38460e1f8cd18fc6d&amp;mpshare=1&amp;scene=23&amp;srcid=0303HrF8UEJNThmdJNHWNSqd#rd" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzI4MjA0NDgxNA==&amp;mid=2650722499&amp;idx=1&amp;sn=b489bb77ba12be14df197fdc77893b22&amp;chksm=f3958022c4e20934aee7516645a415a379275423b1805da63e7419766ad38460e1f8cd18fc6d&amp;mpshare=1&amp;scene=23&amp;srcid=0303HrF8UEJNThmdJNHWNSqd#rd</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Linear-scaling-learning-rate&quot;&gt;&lt;a href=&quot;#Linear-scaling-learning-rate&quot; class=&quot;headerlink&quot; title=&quot;Linear scaling learning rate&quot;&gt;&lt;/a&gt;Li
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>nn.NLLLoss() nn.CrossEntropyLoss() nn.KLDivLoss()的区别</title>
    <link href="http://yoursite.com/2020/08/23/nn-KLDivLoss-%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2020/08/23/nn-KLDivLoss-%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-08-23T12:40:15.000Z</published>
    <updated>2020-08-23T12:41:43.219Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nn-NLLLoss-nn-CrossEntropyLoss-nn-KLDivLoss-的区别"><a href="#nn-NLLLoss-nn-CrossEntropyLoss-nn-KLDivLoss-的区别" class="headerlink" title="nn.NLLLoss() nn.CrossEntropyLoss() nn.KLDivLoss()的区别"></a>nn.NLLLoss() nn.CrossEntropyLoss() nn.KLDivLoss()的区别</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">torch.manual_seed(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><pre><code>&lt;torch._C.Generator at 0x1ea98f1deb0&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input = torch.randn(<span class="number">3</span>, <span class="number">4</span>)  <span class="comment"># 输出假设为三个样本，四种类别</span></span><br><span class="line">input</span><br></pre></td></tr></table></figure><pre><code>tensor([[ 0.6614,  0.2669,  0.0617,  0.6213],        [-0.4519, -0.1661, -1.5228,  0.3817],        [-1.0276, -0.5631, -0.8923, -0.0583]])</code></pre><p>$$\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">softmax = nn.Softmax(dim=<span class="number">1</span>)  <span class="comment"># dim=1按着行向量相加为1</span></span><br><span class="line">softmax(input)</span><br></pre></td></tr></table></figure><pre><code>tensor([[0.5820, 0.1406, 0.1137, 0.1637],        [0.6070, 0.2923, 0.0541, 0.0466],        [0.0815, 0.3453, 0.5165, 0.0567]])</code></pre><p>$$\log(\text{Softmax}(x))$$<br>$$\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.log(softmax(input))</span><br></pre></td></tr></table></figure><pre><code>tensor([[-0.5413, -1.9622, -2.1739, -1.8095],        [-0.4993, -1.2300, -2.9168, -3.0653],        [-2.5078, -1.0633, -0.6606, -2.8699]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">F.log_softmax(input, dim=<span class="number">1</span>)  <span class="comment"># function中的直接计算</span></span><br></pre></td></tr></table></figure><pre><code>tensor([[-0.5413, -1.9622, -2.1739, -1.8095],        [-0.4993, -1.2300, -2.9168, -3.0653],        [-2.5078, -1.0633, -0.6606, -2.8699]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">target = torch.tensor([<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure><p>$$\text{loss}(x, class) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)<br>                       = -x[class] + \log\left(\sum_j \exp(x[j])\right)$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0.8356</span> + <span class="number">2.0189</span> + <span class="number">2.9673</span>) / <span class="number">3</span>  <span class="comment"># 三个样本的目标分别为0, 2, 3，所以三个样本计算的交叉熵的损失为</span></span><br></pre></td></tr></table></figure><pre><code>1.9405999999999999</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.NLLLoss()  <span class="comment"># NLLLoss损失的设置</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss(torch.log(softmax(input)), target)  <span class="comment"># 计算的结果与上面的结果相同</span></span><br></pre></td></tr></table></figure><pre><code>tensor(2.1093)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss(input, target)</span><br></pre></td></tr></table></figure><pre><code>tensor(2.1093)</code></pre><p>$$\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)$$<br>$$l(x,y) = L := { l_1,\dots,l_N }, \quad<br>l_n = y_n \cdot \left( \log y_n - x_n \right)$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.KLDivLoss(reduction=<span class="string">'batchmean'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">target = torch.tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]], dtype=torch.float)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss(F.log_softmax(input, dim=<span class="number">1</span>), target)  <span class="comment"># KL的结果是在目标为one_hot的时候计算的，结果同上面两个计算相同</span></span><br></pre></td></tr></table></figure><pre><code>tensor(2.1093)</code></pre><p>总上nn.CrossEntropyLoss()就是把Softmax-Log-NLLLoss合并为了一步计算。NLLLoss()就是在log似然的基础上直接计算熵，其target是类别的索引数字。KLDivLoss()的计算为Softmax-&gt;Log-&gt;目标类别由索引转为one-hot-&gt;KLDivLoss，计算结果同CrossEntropyLoss()相同。</p><p>[1] <a href="https://blog.csdn.net/qq_22210253/article/details/85229988/" target="_blank" rel="noopener">https://blog.csdn.net/qq_22210253/article/details/85229988/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;nn-NLLLoss-nn-CrossEntropyLoss-nn-KLDivLoss-的区别&quot;&gt;&lt;a href=&quot;#nn-NLLLoss-nn-CrossEntropyLoss-nn-KLDivLoss-的区别&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>cmu11-785-rnn1</title>
    <link href="http://yoursite.com/2020/08/23/cmu11-785-rnn1/"/>
    <id>http://yoursite.com/2020/08/23/cmu11-785-rnn1/</id>
    <published>2020-08-23T09:25:55.000Z</published>
    <updated>2020-08-23T12:57:47.037Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Modelling-Series"><a href="#Modelling-Series" class="headerlink" title="Modelling Series"></a>Modelling Series</h2><p>In many situations one must consider a $\color{red}{series}$ of inputs to produce an output<br>– Outputs too may be a series<br>例如下面的几个例子<br><strong>1、What Did I say?</strong><br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn1.png" height="146" width="755"><br><strong>2、what is he talking about?</strong><br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn2.png"><br><strong>3、Should i invest…</strong><br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn3.png"></p><h2 id="Representational-shortcut"><a href="#Representational-shortcut" class="headerlink" title="Representational shortcut"></a>Representational shortcut</h2><ul><li>在每一个时刻的输入是向量</li><li>每一层有很多神经元(输出层也可能有很多的神经元)</li><li>用一个简单的box来代替以上所有(每一个box实际上代表着有很多层的神经元)  </li></ul><p>如图所示   </p><table rules="none"><tr><td><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn4.png" border="0"></td><td><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn5.png" border="0"></td></tr></table>  <img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn6.png" height="230" width="517"><h2 id="The-stock-predictor"><a href="#The-stock-predictor" class="headerlink" title="The stock predictor"></a>The stock predictor</h2><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn7.png" height="232" width="565">  <ul><li>The sliding predictor<ul><li>Look at the last few days</li><li>This is just a convolutional neural net applied to series data </li></ul></li></ul><p>Also called a <strong>Time-Delay neural network</strong></p><h2 id="Finite-response-model"><a href="#Finite-response-model" class="headerlink" title="Finite-response model"></a>Finite-response model</h2><p>如图所示这是一个输入是$\color{orange}{有限的}$问答系统(finite response system)，今天发生的事情只是影响未来N天的输出。如图中的N为3，则$X(t+3)$的输入不能影响$Y(t+7)$的输出。其中N是系统中的宽度。<br>$$Y_t=f(X_t, X_t-1,…,X_{t-N})$$<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn8.png" height="232" width="565">   </p><p>上述描述只能依赖长度为N的历史信息，但是往往我们需要更长历史信息(Systems often have long-term<br>dependencies)  </p><h2 id="We-want-infinite-memory"><a href="#We-want-infinite-memory" class="headerlink" title="We want infinite memory"></a>We want infinite memory</h2><p>如图所示今天发生的事情可以持续的影响后面的输出(forever)，可能只是对后面的影响越来越弱。<br>$$Y_t=f(X_t, X_t-1,…,X_{t-\infty})$$<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn9.png" height="232" width="565">  </p><p>针对这种问题，课程中老师讲到了RNN出现之前的几种网络。<strong>one-tap NARX network</strong>，<strong>Jordan Network</strong>和<strong>Elman Networks</strong>想做了解可以看课程的slides。下面主要是讲解的RNN。</p><h2 id="An-alternate-model-for-infinite-response-systems-the-state-space-model"><a href="#An-alternate-model-for-infinite-response-systems-the-state-space-model" class="headerlink" title="An alternate model for infinite response systems: the state-space model"></a>An alternate model for infinite response systems: the state-space model</h2><p>模型的公式为<br>$$h_t=f(x_t, h_{t-1})$$ $$y_t=g(h_t)$$<br>$h_t$是网络的状态。模型直接把history信息存储在$h_t$状态信息中，需要定义初始的状态信息$h_{-1}$，状态中存储着过去所有的信息。如下图是一个简单的state-space的模型。<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn10.png" height="232" width="650"> </p><p>在每个时刻的状态信息(绿色的方块)是由当前时刻的输入和上一时刻的状态信息确定。在$t=0$时刻的输入可以一直影响到最后的时刻。又称为<strong>recurrent neural network</strong>，其中所有列的权重都是相同的。上图展示的是单个隐层的循环神经网络(Single hidden layer RNN)，下图是多层的循环神经网络(Multiple recurrent layer RNN)<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn11.png" height="232" width="650"> </p><h2 id="A-Recurrent-Neural-Network"><a href="#A-Recurrent-Neural-Network" class="headerlink" title="A Recurrent Neural Network"></a>A Recurrent Neural Network</h2><p>RNN模型图的简单表示方式<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn12.png" height="360" width="650"><br>下面主要讲解的是三种不同RNN的数学表达<br>1、简单的一层的<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn13.png"><br>2、两层的<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn14.png"><br>3、跨连接的<br><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn15.png"><br>如图所示初始的状态也可以是可以训练的网络参数的一部分。上述对RNN的具体的计算流程用了详细的数学表达。  </p><h2 id="Variants-on-recurrent-nets"><a href="#Variants-on-recurrent-nets" class="headerlink" title="Variants on recurrent nets"></a>Variants on recurrent nets</h2><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn16.png"><img src= "/img/loading.gif" data-src="/2020/08/23/cmu11-785-rnn1/rnn17.png">   ]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Modelling-Series&quot;&gt;&lt;a href=&quot;#Modelling-Series&quot; class=&quot;headerlink&quot; title=&quot;Modelling Series&quot;&gt;&lt;/a&gt;Modelling Series&lt;/h2&gt;&lt;p&gt;In many situat
      
    
    </summary>
    
    
    
      <category term="cmu11-785" scheme="http://yoursite.com/tags/cmu11-785/"/>
    
  </entry>
  
  <entry>
    <title>cs231n-assignment2</title>
    <link href="http://yoursite.com/2020/07/12/cs231n-assignment2/"/>
    <id>http://yoursite.com/2020/07/12/cs231n-assignment2/</id>
    <published>2020-07-12T02:50:07.000Z</published>
    <updated>2020-08-23T12:57:38.824Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>cs231n-assignment3</title>
    <link href="http://yoursite.com/2020/07/11/cs231n-assignment3/"/>
    <id>http://yoursite.com/2020/07/11/cs231n-assignment3/</id>
    <published>2020-07-11T03:06:08.000Z</published>
    <updated>2020-08-23T13:10:34.886Z</updated>
    
    <content type="html"><![CDATA[<p>作业三中总共有五个问题，前两个问题分别是自己实现一个RNN和LSTM来做图像captioning，问题三是对神经网络的几个可视化，问题四是我们经常看到的风格迁移，最后一个问题是生成对抗网络，下面将对每个问题进行详细的阐述。所有作业的实现都已经上传到<a href="https://github.com/VJaGG/cs231n-spring-2019" target="_blank" rel="noopener">GitHub</a>。</p><h2 id="Q1-Image-Captioning-with-Vanilla-RNNs"><a href="#Q1-Image-Captioning-with-Vanilla-RNNs" class="headerlink" title="Q1: Image Captioning with Vanilla RNNs"></a>Q1: Image Captioning with Vanilla RNNs</h2><p>在Q1和Q2所用到的训练数据集是<strong>Microsoft COCO</strong>，其中数据进行了预处理，全部的数据特征都是从VGG-16的fc7层中提取的，VGG网络是在ImageNet数据集上预训练好的。通过VGG网络提取的预处理的特征分别存储在<code>train2014_vgg16_fc7.h5</code>和<code>val2014_vgg16_fc7.h5</code>中。为了在速度和处理时间上节省内存，这里使用<strong>PCA</strong>对提取的特征进行了降维，将VGG-16提取的4096维度降到了512维，存储在<code>train2014_vgg16_fc7_pca.h5</code>和<code>val2014_vgg16_fc7_pca.h5</code>中。为了便于训练每个单词都有一个ID与其对应，这些映射存储在<code>coco2014_vocab.json</code>。下图为训练的数据集。训练中增加了几个特殊的token，在开始和结束的位置分别加了&lt;START&gt;和&lt;END&gt;标签，不常见的单词用&lt;&lt;UNK&gt;来替代，对于长度比较短的在&lt;END&gt;后面用&lt;NULL&gt;来进行补全。</p><body><table rules="none"><tr><td align="center" style="font-size:90%"> &lt;START&gt; a &lt;UNK&gt; bike learning up against the side of a building &lt;END&gt; </td><td align="center" style="font-size:90%"> &lt;START&gt; a desk and chair with a computer and a lamp &lt;END&gt;</td></tr><tr><td><img src= "/img/loading.gif" data-src="/2020/07/11/cs231n-assignment3/test1.jpg"></td><td><img src= "/img/loading.gif" data-src="/2020/07/11/cs231n-assignment3/test2.jpg"></td></tr></table></body>  <p><strong>RNN</strong>的实现代码在<code>cs231n/rnn_layers.py</code>中，其中<strong>RNN</strong>的主要公式如下：  </p><center>$z=W_xx_t + W_hh_{t-1}+b$</center>  <center>$h_{t} = \tanh(z)$</center>  作业中会对RNN的前向传播和反向传播分别进行实现，前向传播和反向传播的代码如下:  <p>前向传播    </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span><span class="params">(x, prev_h, Wx, Wh, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Run the forward pass for a single timestep of a vanilla RNN that uses a tanh</span></span><br><span class="line"><span class="string">    activation function.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input data has dimension D, the hidden state has dimension H, and we use</span></span><br><span class="line"><span class="string">    a minibatch size of N.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data for this timestep, of shape (N, D).</span></span><br><span class="line"><span class="string">    - prev_h: Hidden state from previous timestep, of shape (N, H) </span></span><br><span class="line"><span class="string">    - Wx: Weight matrix for input-to-hidden connections, of shape (D, H) </span></span><br><span class="line"><span class="string">    - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H) </span></span><br><span class="line"><span class="string">    - b: Biases of shape (H,) </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - next_h: Next hidden state, of shape (N, H) </span></span><br><span class="line"><span class="string">    - cache: Tuple of values needed for the backward pass. </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    next_h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    z = np.dot(x, Wx) + np.dot(prev_h, Wh) + b</span><br><span class="line">    next_h = np.tanh(z)</span><br><span class="line">    cache = (x, prev_h, Wx, Wh, b, next_h)</span><br><span class="line">    <span class="keyword">return</span> next_h, cache</span><br></pre></td></tr></table></figure><p>反向传播  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span><span class="params">(dnext_h, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Backward pass for a single timestep of a vanilla RNN.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dnext_h: Gradient of loss with respect to next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Cache object from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradients of input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dprev_h: Gradients of previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradients of input-to-hidden weights, of shape (D, H)</span></span><br><span class="line"><span class="string">    - dWh: Gradients of hidden-to-hidden weights, of shape (H, H)</span></span><br><span class="line"><span class="string">    - db: Gradients of bias vector, of shape (H,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dprev_h, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    (x, prev_h, Wx, Wh, b, next_h) = cache</span><br><span class="line">    dz = (<span class="number">1</span> -  next_h**<span class="number">2</span>) * dnext_h</span><br><span class="line">    dx = np.dot(dz, Wx.T)</span><br><span class="line">    dprev_h = np.dot(dz, Wh.T)</span><br><span class="line">    dWx = np.dot(x.T, dz)</span><br><span class="line">    dWh = np.dot(prev_h.T, dz)</span><br><span class="line">    db = np.sum(dz, axis=<span class="number">0</span>) </span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>以上实现的反向传播和前向传播只是针对于当前时刻的。为了训练需要将时序T加入到RNN的前项传播中，加入时序的前向传播和反向传播如下：  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(x, h0, Wx, Wh, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Run a vanilla RNN forward on an entire sequence of data. We assume an input</span></span><br><span class="line"><span class="string">    sequence composed of T vectors, each of dimension D. The RNN uses a hidden</span></span><br><span class="line"><span class="string">    size of H, and we work over a minibatch containing N sequences. After running</span></span><br><span class="line"><span class="string">    the RNN forward, we return the hidden states for all timesteps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data for the entire timeseries, of shape (N, T, D).</span></span><br><span class="line"><span class="string">    - h0: Initial hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)</span></span><br><span class="line"><span class="string">    - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)</span></span><br><span class="line"><span class="string">    - b: Biases of shape (H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - h: Hidden states for the entire timeseries, of shape (N, T, H).</span></span><br><span class="line"><span class="string">    - cache: Values needed in the backward pass</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    h = []</span><br><span class="line">    cache = []</span><br><span class="line">    h.append(h0)</span><br><span class="line">    N, T, _ = x.shape</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T):</span><br><span class="line">        x_t = x[:,t,:]</span><br><span class="line">        prev_h = h[t]</span><br><span class="line">        next_h, cache_t = rnn_step_forward(x_t, prev_h, Wx, Wh, b)</span><br><span class="line">        h.append(next_h)</span><br><span class="line">        cache.append(cache_t)</span><br><span class="line">    h = np.hstack(h[<span class="number">1</span>:]).reshape(N, T, <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(dh, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Compute the backward pass for a vanilla RNN over an entire sequence of data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dh: Upstream gradients of all hidden states, of shape (N, T, H). 下一层网络的梯度信息</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    NOTE: 'dh' contains the upstream gradients produced by the </span></span><br><span class="line"><span class="string">    individual loss functions at each timestep, *not* the gradients</span></span><br><span class="line"><span class="string">    being passed between timesteps (which you'll have to compute yourself</span></span><br><span class="line"><span class="string">    by calling rnn_step_backward in a loop).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of inputs, of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - dh0: Gradient of initial hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weights, of shape (D, H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weights, of shape (H, H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (H,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dh0, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, H = dh.shape</span><br><span class="line">    dx = []</span><br><span class="line">    dprev_h = <span class="number">0</span></span><br><span class="line">    dWx = <span class="number">0</span></span><br><span class="line">    dWh = <span class="number">0</span></span><br><span class="line">    db = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">        cache_cur = cache[t]</span><br><span class="line">        dnext_h = dprev_h + dh[:, t, :]</span><br><span class="line">        dcurx, dprev_h, dWx_, dWh_, db_ = rnn_step_backward(dnext_h, cache_cur)</span><br><span class="line">        dWx += dWx_</span><br><span class="line">        dWh += dWh_</span><br><span class="line">        db += db_</span><br><span class="line">        dx.append(dcurx)</span><br><span class="line">    dx.reverse()</span><br><span class="line">    dx = np.hstack(dx).reshape(N, T, <span class="number">-1</span>)</span><br><span class="line">    dh0 = dprev_h</span><br><span class="line">    <span class="keyword">return</span> dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure><p>这里需要注意的主要是RNN的反向传播的实现，在反向传播中有下一层传回来的时序的梯度这里是dh，可以看到它的shape大小为(N, T, H)。在前向传播的过程中隐层的状态信息分两条线路，一部分传到下个时刻，一部分传到下一层网络，如图所示：  </p><img src= "/img/loading.gif" data-src="/2020/07/11/cs231n-assignment3/RNN.png" width="70%" height="70%">对于h1来说分两部分，分别传到下层和T2时刻的隐藏层输入，所以在反向传播的时候h1有两部分的梯度一部分是下一层的，实现的时候为dh[:, t, :]，一部分为下一个时刻的为dprev_h。同时对于T时刻的状态，dprev_h=0。<h2 id="Q2-Image-Captioning-with-LSTMs"><a href="#Q2-Image-Captioning-with-LSTMs" class="headerlink" title="Q2: Image Captioning with LSTMs"></a>Q2: Image Captioning with LSTMs</h2><p>LSTM训练所用到的数据集同RNN相同，LSTM同RNN相同，在每个时刻接受一个输入和上一层的隐藏层的状态，LSTM也保持着之前的状态在<em>cell state</em> $c_{t-1}\in\mathbb{R}^H$ 。 在LSTM中可以学习的参数有两个一个是<em>input-to-hidden</em> 的权重 $W_x\in\mathbb{R}^{4H\times D}$, 另一个是 <em>hidden-to-hidden</em> 的权重 $W_h\in\mathbb{R}^{4H\times H}$ 还有一个 <em>bias vector</em> $b\in\mathbb{R}^{4H}$。这边具体的描述直接copy的代码页的描述不做翻译了。</p><p>At each timestep we first compute an <em>activation vector</em> $a\in\mathbb{R}^{4H}$ as $a=W_xx_t + W_hh_{t-1}+b$. We then divide this into four vectors $a_i,a_f,a_o,a_g\in\mathbb{R}^H$ where $a_i$ consists of the first $H$ elements of $a$, $a_f$ is the next $H$ elements of $a$, etc. We then compute the <em>input gate</em> $g\in\mathbb{R}^H$, <em>forget gate</em> $f\in\mathbb{R}^H$, <em>output gate</em> $o\in\mathbb{R}^H$ and <em>block input</em> $g\in\mathbb{R}^H$ as<br>$$<br>i = \sigma(a_i) \hspace{4pc} f = \sigma(a_f) \hspace{4pc}  o = \sigma(a_o) \hspace{4pc} g = \tanh(a_g)<br>$$<br>where $\sigma$ is the sigmoid function and $\tanh$ is the hyperbolic tangent, both applied elementwise.<br>Finally we compute the next cell state $c_t$ and next hidden state $h_t$ as<br>$$<br>c_{t} = f\odot c_{t-1} + i\odot g \hspace{4pc}<br>h_t = o\odot\tanh(c_t)<br>$$<br>where $\odot$ is the elementwise product of vectors.<br>In the rest of the notebook we will implement the LSTM update rule and apply it to the image captioning task.<br>In the code, we assume that data is stored in batches so that $X_t \in \mathbb{R}^{N\times D}$, and will work with <em>transposed</em> versions of the parameters: $W_x \in \mathbb{R}^{D \times 4H}$, $W_h \in \mathbb{R}^{H\times 4H}$ so that activations $A \in \mathbb{R}^{N\times 4H}$ can be computed efficiently as $A = X_t W_x + H_{t-1} W_h$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_forward</span><span class="params">(x, prev_h, prev_c, Wx, Wh, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Forward pass for a single timestep of an LSTM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The input data has dimension D, the hidden state has dimension H, and we use</span></span><br><span class="line"><span class="string">    a minibatch size of N.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that a sigmoid() function has already been provided for you in this file.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - prev_h: Previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - prev_c: previous cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Input-to-hidden weights, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - Wh: Hidden-to-hidden weights, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - b: Biases, of shape (4H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - next_h: Next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - next_c: Next cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Tuple of values needed for backward pass.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    next_h, next_c, cache = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    a = np.dot(x, Wx) + np.dot(prev_h, Wh) + b</span><br><span class="line">    a_i, a_f, a_o, a_g = np.hsplit(a, <span class="number">4</span>)</span><br><span class="line">    i = sigmoid(a_i)</span><br><span class="line">    f = sigmoid(a_f)</span><br><span class="line">    o = sigmoid(a_o)</span><br><span class="line">    g = np.tanh(a_g)</span><br><span class="line">    next_c = f * prev_c + i * g</span><br><span class="line">    next_h = o * np.tanh(next_c)</span><br><span class="line">    cache = (next_h, o, f, prev_c, i, g, x, Wx, prev_h, Wh)</span><br><span class="line">    <span class="keyword">return</span> next_h, next_c, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_backward</span><span class="params">(dnext_h, dnext_c, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Backward pass for a single timestep of an LSTM.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dnext_h: Gradients of next hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dnext_c: Gradients of next cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - cache: Values from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of input data, of shape (N, D)</span></span><br><span class="line"><span class="string">    - dprev_h: Gradient of previous hidden state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dprev_c: Gradient of previous cell state, of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weights, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (4H,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dprev_h, dprev_c, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    (next_h, o, f, prev_c, i, g, x, Wx, prev_h, Wh) = cache</span><br><span class="line">    dnext_c += dnext_h * o * (<span class="number">1</span> - (next_h / o)**<span class="number">2</span>)</span><br><span class="line">    dprev_c = dnext_c * f</span><br><span class="line">    df = dnext_c * prev_c</span><br><span class="line">    do = dnext_h * next_h / o</span><br><span class="line">    di = dnext_c * g</span><br><span class="line">    dg = dnext_c * i</span><br><span class="line">    da_i = di * i * (<span class="number">1</span>-i)</span><br><span class="line">    da_f = df * f * (<span class="number">1</span>-f)</span><br><span class="line">    da_o = do * o * (<span class="number">1</span>-o)</span><br><span class="line">    da_g = dg * (<span class="number">1</span>-g**<span class="number">2</span>)</span><br><span class="line">    da = np.concatenate((da_i, da_f, da_o, da_g), axis=<span class="number">1</span>)</span><br><span class="line">    db = np.sum(da, axis=<span class="number">0</span>)</span><br><span class="line">    dx = np.dot(da, Wx.T)</span><br><span class="line">    dWx = np.dot(x.T, da)</span><br><span class="line">    dprev_h = np.dot(da, Wh.T)</span><br><span class="line">    dWh = np.dot(prev_h.T, da)</span><br><span class="line">    <span class="keyword">return</span> dx, dprev_h, dprev_c, dWx, dWh, db</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span><span class="params">(x, h0, Wx, Wh, b)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Forward pass for an LSTM over an entire sequence of data. We assume an input</span></span><br><span class="line"><span class="string">    sequence composed of T vectors, each of dimension D. The LSTM uses a hidden</span></span><br><span class="line"><span class="string">    size of H, and we work over a minibatch containing N sequences. After running</span></span><br><span class="line"><span class="string">    the LSTM forward, we return the hidden states for all timesteps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Note that the initial cell state is passed as input, but the initial cell</span></span><br><span class="line"><span class="string">    state is set to zero. Also note that the cell state is not returned; it is</span></span><br><span class="line"><span class="string">    an internal variable to the LSTM and is not accessed from outside.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - x: Input data of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - h0: Initial hidden state of shape (N, H)</span></span><br><span class="line"><span class="string">    - Wx: Weights for input-to-hidden connections, of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - b: Biases of shape (4H,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - h: Hidden states for all timesteps of all sequences, of shape (N, T, H)</span></span><br><span class="line"><span class="string">    - cache: Values needed for the backward pass.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    h, cache = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    N, T, D = x.shape</span><br><span class="line">    prev_h = h0</span><br><span class="line">    prev_c = <span class="number">0</span></span><br><span class="line">    cache = []</span><br><span class="line">    h = []</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> range(T):</span><br><span class="line">        x_t = x[:, t, :]</span><br><span class="line">        next_h, next_c, cache_ = lstm_step_forward(x_t, prev_h, prev_c, Wx, Wh, b)</span><br><span class="line">        prev_h = next_h</span><br><span class="line">        prev_c = next_c</span><br><span class="line">        cache.append(cache_)</span><br><span class="line">        h.append(next_h)</span><br><span class="line">    </span><br><span class="line">    h = np.hstack(h).reshape(N, T, <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> h, cache</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span><span class="params">(dh, cache)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Backward pass for an LSTM over an entire sequence of data.]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">    - dh: Upstream gradients of hidden states, of shape (N, T, H)</span></span><br><span class="line"><span class="string">    - cache: Values from the forward pass</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns a tuple of:</span></span><br><span class="line"><span class="string">    - dx: Gradient of input data of shape (N, T, D)</span></span><br><span class="line"><span class="string">    - dh0: Gradient of initial hidden state of shape (N, H)</span></span><br><span class="line"><span class="string">    - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H)</span></span><br><span class="line"><span class="string">    - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H)</span></span><br><span class="line"><span class="string">    - db: Gradient of biases, of shape (4H,)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dx, dh0, dWx, dWh, db = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    (N, T, H) = dh.shape</span><br><span class="line">    dprev_h = <span class="number">0</span></span><br><span class="line">    dprev_c = <span class="number">0</span></span><br><span class="line">    dx = []</span><br><span class="line">    dWx = <span class="number">0</span>; dWh = <span class="number">0</span>; db = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> reversed(range(T)):</span><br><span class="line">        cache_ = cache[t]</span><br><span class="line">        dnext_h = dh[:, t, :] + dprev_h</span><br><span class="line">        dnext_c = dprev_c</span><br><span class="line">        dx_, dprev_h, dprev_c, dWx_, dWh_, db_ = lstm_step_backward(dnext_h, dnext_c, cache_)</span><br><span class="line">        dx.append(dx_)</span><br><span class="line">        dWx += dWx_</span><br><span class="line">        dWh += dWh_</span><br><span class="line">        db += db_</span><br><span class="line">        </span><br><span class="line">    dh0 = dprev_h</span><br><span class="line">    dx = np.hstack(list(reversed(dx))).reshape(N, T, <span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> dx, dh0, dWx, dWh, db</span><br></pre></td></tr></table></figure><h2 id="Q3-Network-Visualization-Saliency-maps-Class-Visualization-and-Fooling-Images"><a href="#Q3-Network-Visualization-Saliency-maps-Class-Visualization-and-Fooling-Images" class="headerlink" title="Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images"></a>Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images</h2><h2 id="Q4-Style-Transfer"><a href="#Q4-Style-Transfer" class="headerlink" title="Q4: Style Transfer"></a>Q4: Style Transfer</h2><h2 id="Q5-Generative-Adversarial-Networks"><a href="#Q5-Generative-Adversarial-Networks" class="headerlink" title="Q5: Generative Adversarial Networks"></a>Q5: Generative Adversarial Networks</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;作业三中总共有五个问题，前两个问题分别是自己实现一个RNN和LSTM来做图像captioning，问题三是对神经网络的几个可视化，问题四是我们经常看到的风格迁移，最后一个问题是生成对抗网络，下面将对每个问题进行详细的阐述。所有作业的实现都已经上传到&lt;a href=&quot;http
      
    
    </summary>
    
    
    
      <category term="cs231n" scheme="http://yoursite.com/tags/cs231n/"/>
    
  </entry>
  
  <entry>
    <title>hello world</title>
    <link href="http://yoursite.com/2020/07/10/hello-world/"/>
    <id>http://yoursite.com/2020/07/10/hello-world/</id>
    <published>2020-07-10T13:52:31.640Z</published>
    <updated>2020-07-12T14:23:46.369Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
